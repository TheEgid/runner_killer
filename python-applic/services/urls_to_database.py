import time
from typing import List, Dict, Any
from prefect import task # type: ignore
from prefect.cache_policies import NO_CACHE # type: ignore

from models import LightTask


@task(cache_policy=NO_CACHE, retries=2, retry_delay_seconds=5)
def process_single_url(task_obj: LightTask, vector_ingestion, logger) -> Dict[str, Any]:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω URL —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø–æ–≤—Ç–æ—Ä–æ–º –ø—Ä–∏ RateLimitError.
    """
    max_retries = 5
    delay = 10  # —Å–µ–∫—É–Ω–¥ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏ –ø—Ä–∏ rate limit

    for attempt in range(1, max_retries + 1):
        try:
            logger.info(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ {task_obj.url} (–ø–æ–ø—ã—Ç–∫–∞ {attempt})")
            success = vector_ingestion.ingest_url(task_obj)
            if success:
                return {"url": task_obj.url, "status": "completed"}
            else:
                return {"url": task_obj.url, "status": "error", "error": "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å"}
        # except Error:
        #     logger.warning(f"‚ö†Ô∏è Rate limit –¥–ª—è {task_obj.url}, –ø–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {delay}s (–ø–æ–ø—ã—Ç–∫–∞ {attempt})")
        #     time.sleep(delay)
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è {task_obj.url}: {e}")
            return {"url": task_obj.url, "status": "error", "error": str(e)}

    # –ï—Å–ª–∏ –≤—Å–µ retries –∏—Å—á–µ—Ä–ø–∞–Ω—ã
    return {"url": task_obj.url, "status": "error", "error": "Rate limit –∏—Å—á–µ—Ä–ø–∞–Ω –ø–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—ã—Ç–æ–∫"}


@task(cache_policy=NO_CACHE, retries=3, retry_delay_seconds=10)
def urls_to_database(tasks_to_process: List, vector_ingestion, logger) -> Dict[str, List[Dict[str, Any]]]:
    logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {len(tasks_to_process)} URL")

    processed_results = {
        "success": [],
        "errors": [],
        "skipped": []
    }

    chunk_size = 2
    chunks = [tasks_to_process[i:i + chunk_size] for i in range(0, len(tasks_to_process), chunk_size)]

    for chunk_num, chunk in enumerate(chunks, 1):
        logger.info(f"üîß –û–±—Ä–∞–±–æ—Ç–∫–∞ {chunk_num}/{len(chunks)} ({len(chunk)} URL)")

        results_futures = [
            process_single_url.submit(task_obj, vector_ingestion, logger)
            for task_obj in chunk
        ]

        chunk_results = [f.result() for f in results_futures]

        # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for res in chunk_results:
            if res["status"] == "completed":
                processed_results["success"].append(res)
            elif res.get("error") == "Rate limit –∏—Å—á–µ—Ä–ø–∞–Ω –ø–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—ã—Ç–æ–∫":
                processed_results["skipped"].append(res)
            else:
                processed_results["errors"].append(res)

    logger.info(f"‚úÖ –í—Å–µ URL –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã. –ò—Ç–æ–≥–æ —É—Å–ø–µ—à–Ω—ã—Ö: {len(processed_results['success'])}, "
                f"–æ—à–∏–±–æ–∫: {len(processed_results['errors'])}, –ø—Ä–æ–ø—É—â–µ–Ω–æ: {len(processed_results['skipped'])}")
    return processed_results
