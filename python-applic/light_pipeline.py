from dataclasses import asdict
import os
from prefect.task_runners import ConcurrentTaskRunner # type: ignore
from prefect import get_run_logger # type: ignore
from cache import Cache
from prefect import task # type: ignore
from models import LightTask
from services.google_sheets import GoogleSheetsService
from services.urls_to_database import urls_to_database
from services.vector_store import VectorStoreService
from services.vector_ingestion_service import VectorIngestionService


@task(retries=3, retry_delay_seconds=10)
def read_light_tasks(sheets_service: GoogleSheetsService, spreadsheet_id: str, sheet_name: str) -> list[LightTask]:
    """–ß—Ç–µ–Ω–∏–µ –∑–∞–¥–∞—á –∏–∑ Google Sheets"""
    data = sheets_service.read_sheets(spreadsheet_id, sheet_name)
    data = data if isinstance(data, list) else [data]

    return [
        LightTask(
            status=item.get("status", ""),
            url=item.get("url", "")
        )
        for item in data[:3450]  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–µ–π
    ]


class LightPipeline:
    def __init__(self, resume: bool = True):
        self.resume = resume
        self.cache = Cache()
        self.sheets_service = GoogleSheetsService()
        self.logger = None

    def _get_vector_ingestion(self, spreadsheet_id: str, sheet_name: str) -> VectorIngestionService:
        """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏"""
        if not self.logger:
            raise ValueError("Logger –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

        vector_store = VectorStoreService(logger=self.logger)
        return VectorIngestionService(
            vector_store, self.sheets_service, spreadsheet_id, sheet_name, self.logger
        )

    def run(self, sheet_name: str = "Main"):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        self.logger = get_run_logger()
        spreadsheet_id = os.getenv("GOOGLE_LIGHT_ID")

        if not spreadsheet_id:
            raise ValueError("–ù–µ –∑–∞–¥–∞–Ω GOOGLE_LIGHT_ID")

        self.logger.info("üöÄ –ó–∞–ø—É—Å–∫ LIGHT –ø–∞–π–ø–ª–∞–π–Ω–∞...")

        # –≠—Ç–∞–ø 1: –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        light_tasks = self._get_light_tasks(spreadsheet_id, sheet_name)
        self.logger.info(f"üìñ –ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(light_tasks)} –∑–∞–¥–∞–Ω–∏–π")

        # –≠—Ç–∞–ø 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ URL
        valid_tasks, tasks_to_process, skipped_count = self._filter_tasks(light_tasks)

        self.logger.info(
            f"üîó –í–∞–ª–∏–¥–Ω—ã—Ö URL: {len(valid_tasks)}, "
            f"–∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {len(tasks_to_process)}, "
            f"–ø—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_count}"
        )

        # –≠—Ç–∞–ø 3: –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
        processed_results = self._process_urls(tasks_to_process, spreadsheet_id, sheet_name)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        stats = self._log_statistics(valid_tasks, tasks_to_process, processed_results, skipped_count)

        return {
            "light_tasks": light_tasks,
            "processed_results": processed_results,
            "stats": stats
        }

    def _get_light_tasks(self, spreadsheet_id: str, sheet_name: str) -> list[LightTask]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∑–∞–¥–∞—á (—Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º –ø—Ä–∏ resume=True)"""
        cache_key = "0_a_light_tasks"

        if self.resume:
            cached_tasks = self.cache.get(cache_key)
            if cached_tasks:
                return [LightTask(**task) for task in cached_tasks]

        # –ß—Ç–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        tasks = read_light_tasks(self.sheets_service, spreadsheet_id, sheet_name)

        if self.resume:
            self.cache.set(cache_key, [asdict(task) for task in tasks])

        return tasks

    def _filter_tasks(self, light_tasks: list[LightTask]) -> tuple[list, list, int]:
        """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–∞–¥–∞—á –ø–æ —Å—Ç–∞—Ç—É—Å—É –∏ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ URL"""
        valid_tasks = [t for t in light_tasks if t.url and t.url.strip()]

        completed_statuses = {"completed", "error"}
        tasks_to_process = [
            t for t in valid_tasks
            if str(t.status).strip().lower() not in completed_statuses
        ]

        skipped_count = len(valid_tasks) - len(tasks_to_process)

        return valid_tasks, tasks_to_process, skipped_count

    def _process_urls(self, tasks_to_process: list[LightTask], spreadsheet_id: str, sheet_name: str) -> dict:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ URL —á–µ—Ä–µ–∑ —Å–µ—Ä–≤–∏—Å –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏"""
        cache_key = "0_b_light_processed_results"

        if self.resume:
            cached_results = self.cache.get(cache_key)
            if cached_results:
                return cached_results

        vector_ingestion = self._get_vector_ingestion(spreadsheet_id, sheet_name)
        results = urls_to_database(tasks_to_process, vector_ingestion, self.logger)

        if self.resume:
            self.cache.set(cache_key, results)

        return results

    def _log_statistics(self, valid_tasks: list, tasks_to_process: list,
                        processed_results: dict, skipped_count: int) -> dict:
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏ –æ—à–∏–±–æ–∫"""
        stats = {
            "total_found": len(valid_tasks),
            "total_processed": len(tasks_to_process),
            "success": len(processed_results["success"]),
            "errors": len(processed_results["errors"]),
            "skipped": skipped_count,
        }

        self.logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats}")

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫ (–ø–µ—Ä–≤—ã–µ 5)
        if processed_results["errors"]:
            self.logger.warning("‚ùå –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ URL:")
            error_samples = ", ".join(
                f"{err['url']}: {err['error']}"
                for err in processed_results["errors"][:5]
            )
            self.logger.warning(error_samples)

        return stats
